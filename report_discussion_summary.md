# 📄 檢舉與安全機制討論摘要 (Summary of Discussion)

**日期**: 2025-12-17
**主題**: 兒童圖片生成器 (Kids Vocabulary Generator) - 異常資料處理與安全防護

---

## 1. 核心議題
*   **議題 A**: 既有的檢舉功能僅標記圖片，未移除壞資料，導致使用者查詢時可能再次看到被檢舉的內容。
*   **議題 B**: AI 有時會生成不適合兒童（恐怖、陰暗、過度寫實）的圖片或教案。
*   **議題 C**: 單純刪除資料無法保留證據供後續分析優化。

## 2. 討論過程與決策

### 2.1 刪除 vs. 封存 (Soft Delete vs. Hard Delete)
*   **使用者觀點**: 不希望直接刪除資料，應設計搬移或改名的機制，以保留資料供日後分析。
*   **決策**: 採用 **「封存後刪除 (Archive & Delete)」** 策略。
    1.  先將壞的資料（資料庫紀錄 + 圖片檔案）完整複製到 `archive` 區域。
    2.  確認複製成功後，才刪除主區域的資料。
    3.  此舉達成「前台看不到 (解決問題)」與「後台留底 (保留分析)」的雙重目標。

### 2.2 檢舉範圍 (Scope of Report)
*   **討論**: 圖片和文字說明可能只有其中一項有問題，是否分開處理？
*   **決策**: 採 **「整筆重置」** 策略。
    *   考量到 AI 圖文通常是基於同一組 Prompt 生成，具高度相關性。
    *   且為了確保品質與安全性，若有任一項被社群檢舉，直接讓 AI 重新思考並生成全新的圖文組合是成本最低且最安全的做法。

### 2.3 內容安全 (Content Safety)
*   **問題**: 如何預防生成不當內容？
*   **決策**: 實施 **Prompt Guardrails (提示詞護欄)**。
    *   在 V2 生成流程中，強制在 Prompt 結尾加上安全後綴：
    *   `cute kid-friendly style, soft colors, warm lighting, G-rated, no scary elements`
    *   以此強制模型風格趨向可愛、柔和，避免恐怖谷效應。

## 3. 系統變更總結

| 項目 | 變更內容 | 目的 |
| :--- | :--- | :--- |
| **資料庫 (DB)** | 新增 `mnemonic_generations_archive` 集合 | 存放被檢舉下架的歷史資料 |
| **檔案存儲 (File)** | 新增 GitHub `moveImage` 功能 | 將圖片檔移至 `archive/` 資料夾 |
| **檢舉邏輯** | 票數達標 -> 封存 DB -> 搬移檔案 -> 刪除主資料 | 確保壞資料從前台消失，觸發重製 |
| **生成邏輯** | 增加強制性 Safety Suffix | 預防性攔截恐怖風格圖片 |
